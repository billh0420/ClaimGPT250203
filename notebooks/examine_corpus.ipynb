{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e321e80-6239-4c25-8c2d-4e9559cf7ca0",
   "metadata": {},
   "source": [
    "# Examine corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f01dfbb-4467-4830-9d9a-911e45ac0567",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/hale/PycharmProjects/ClaimGPT250203/notebooks'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36858331-24cc-4d47-8f27-ccc2fa59b025",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import random\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24457df9-c74d-4441-aa53-7f373d138786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_folder_path=/Users/hale/PycharmProjects/ClaimGPT250203/math_gpt_output/main_claim\n",
      "corpus_folder_path=/Users/hale/PycharmProjects/ClaimGPT250203/math_gpt_output/main_claim/corpus\n",
      "corpus_file_path=/Users/hale/PycharmProjects/ClaimGPT250203/math_gpt_output/main_claim/corpus/corpus.txt\n",
      "claim_corpus_file_path=/Users/hale/PycharmProjects/ClaimGPT250203/math_gpt_output/main_claim/corpus/claim_corpus.txt\n"
     ]
    }
   ],
   "source": [
    "output_folder_path = Path('../math_gpt_output/main_claim/').resolve()\n",
    "corpus_folder_path = output_folder_path.joinpath('corpus')\n",
    "corpus_file_path = corpus_folder_path.joinpath('corpus.txt')\n",
    "claim_corpus_file_path = corpus_folder_path.joinpath('claim_corpus.txt')\n",
    "print(f'output_folder_path={output_folder_path}')\n",
    "print(f'corpus_folder_path={corpus_folder_path}')\n",
    "print(f'corpus_file_path={corpus_file_path}')\n",
    "print(f'claim_corpus_file_path={claim_corpus_file_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e570cc6-b4f9-4010-a974-c0b7a09a665d",
   "metadata": {},
   "source": [
    "## claim_corpus\n",
    "\n",
    "Each row in the claim_corpus consists of a ref and a dictum.\n",
    "\n",
    "The ref is the justification of the conclusion from the given premises.\n",
    "\n",
    "I don't use the claim_corpus since the conclusion does not uniquely follow from the premises.\n",
    "\n",
    "Instead, I use the corpus which is a subset of the claim_corpus where there is an obvious conclusion from the premises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40c8b094-5f7c-49c8-bde6-6cb996b5edfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_claim_corpus_row(claim_corpus_row):\n",
    "    label, dictum = claim_corpus_row.split(' ', maxsplit=1)\n",
    "    x = re.split(r\"(?=<\\|start_claim\\|> | <\\|given\\|> | <\\|conclude\\|> | <\\|end_claim\\|>)\", dictum)\n",
    "    print(f'--- ref: {label} ---')\n",
    "    for i, item in enumerate(x):\n",
    "        if i == 0:\n",
    "            assert item == ''\n",
    "        else:\n",
    "            print(f'{i:2}: {item}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c99ebd0-77c5-4dac-973b-004e84dc1b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create claim_corpus_lines\n",
    "with open(claim_corpus_file_path, \"r\") as file:\n",
    "    claim_corpus_lines = file.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a16eb09a-6062-4115-86b7-03658f25df29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ax-mp: <|start_claim|> <|given|> |- ph <|given|> |- ( ph -> ( ps -> ch ) ) <|conclude|> |- ( ps -> ch ) <|end_claim|>\n",
      "ax-mp: <|start_claim|> <|given|> |- ps <|given|> |- ( ps -> ch ) <|conclude|> |- ch <|end_claim|>\n",
      "ax-mp: <|start_claim|> <|given|> |- ph <|given|> |- ( ph -> ps ) <|conclude|> |- ps <|end_claim|>\n",
      "ax-mp: <|start_claim|> <|given|> |- ps <|given|> |- ( ps -> ch ) <|conclude|> |- ch <|end_claim|>\n",
      "ax-1: <|start_claim|> <|conclude|> |- ( ph -> ( ps -> ph ) ) <|end_claim|>\n"
     ]
    }
   ],
   "source": [
    "# print first 5 lines of claim_corpus_lines\n",
    "for line in claim_corpus_lines[0:5]:\n",
    "    label, corpus_line = line.split(' ', maxsplit=1)\n",
    "    print(f'{label}: {corpus_line}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02820272-f83a-4395-a17f-9a8bdcd429ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#claim_corpus_lines=2923354\n"
     ]
    }
   ],
   "source": [
    "print(f'#claim_corpus_lines={len(claim_corpus_lines)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38d8b66a-3387-4547-885d-7dcab63af9b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ref: fourierdlem2 ---\n",
      " 1: <|start_claim|>\n",
      " 2:  <|given|> |- P = ( m e. NN |-> { p e. ( RR ^m ( 0 ... m ) ) | ( ( ( p ` 0 ) = A /\\ ( p ` m ) = B ) /\\ A. i e. ( 0 ..^ m ) ( p ` i ) < ( p ` ( i + 1 ) ) ) } )\n",
      " 3:  <|conclude|> |- ( M e. NN -> ( Q e. ( P ` M ) <-> ( Q e. ( RR ^m ( 0 ... M ) ) /\\ ( ( ( Q ` 0 ) = A /\\ ( Q ` M ) = B ) /\\ A. i e. ( 0 ..^ M ) ( Q ` i ) < ( Q ` ( i + 1 ) ) ) ) ) )\n",
      " 4:  <|end_claim|>\n",
      "--- ref: nfan ---\n",
      " 1: <|start_claim|>\n",
      " 2:  <|given|> |- F/ i ph\n",
      " 3:  <|given|> |- F/ i f e. X_ i e. X ( ( A ` i ) [,) ( B ` i ) )\n",
      " 4:  <|conclude|> |- F/ i ( ph /\\ f e. X_ i e. X ( ( A ` i ) [,) ( B ` i ) ) )\n",
      " 5:  <|end_claim|>\n",
      "--- ref: a1i ---\n",
      " 1: <|start_claim|>\n",
      " 2:  <|given|> |- 0 <_ 2\n",
      " 3:  <|conclude|> |- ( N e. NN -> 0 <_ 2 )\n",
      " 4:  <|end_claim|>\n"
     ]
    }
   ],
   "source": [
    "# pretty print some random rows\n",
    "for _ in range(3):\n",
    "    index = random.randint(0, len(claim_corpus_lines))\n",
    "    claim_corpus_row = claim_corpus_lines[index]\n",
    "    print_claim_corpus_row(claim_corpus_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75741ca-2373-4541-a4ff-f53171dd96a9",
   "metadata": {},
   "source": [
    "## corpus\n",
    "\n",
    "Each row of the corpus consists of a dictum.\n",
    "\n",
    "The model will be trained on the dictums.\n",
    "\n",
    "A prompt will consist of a dictum to the token <\\|conclude\\|>.\n",
    "The reply will be the remaining part of the dictum ending with the token <\\|end_claim\\|>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d68c95a3-cdf9-46f2-b81a-5628c4119883",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_corpus_row(corpus_row):\n",
    "    x = re.split(r\"(?=<\\|start_claim\\|> | <\\|given\\|> | <\\|conclude\\|> | <\\|end_claim\\|>)\", corpus_row)\n",
    "    for i, item in enumerate(x):\n",
    "        if i == 0:\n",
    "            assert item == ''\n",
    "        else:\n",
    "            print(f'{i:2}: {item}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2fdd6da1-510f-43b1-ae2f-4f25b81934c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create corpus_lines\n",
    "with open(corpus_file_path, \"r\") as file:\n",
    "    corpus_lines = file.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6edcb3ea-e429-4a7d-80d4-bf00cbc9053e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|start_claim|>: <|given|> |- ph <|given|> |- ( ph -> ( ps -> ch ) ) <|conclude|> |- ( ps -> ch ) <|end_claim|>\n",
      "<|start_claim|>: <|given|> |- ps <|given|> |- ( ps -> ch ) <|conclude|> |- ch <|end_claim|>\n",
      "<|start_claim|>: <|given|> |- ph <|given|> |- ( ph -> ps ) <|conclude|> |- ps <|end_claim|>\n",
      "<|start_claim|>: <|given|> |- ps <|given|> |- ( ps -> ch ) <|conclude|> |- ch <|end_claim|>\n",
      "<|start_claim|>: <|given|> |- ph <|given|> |- ( ph -> ( ps -> ph ) ) <|conclude|> |- ( ps -> ph ) <|end_claim|>\n"
     ]
    }
   ],
   "source": [
    "# print first 5 lines of corpus_lines\n",
    "for line in corpus_lines[0:5]:\n",
    "    label, corpus_line = line.split(' ', maxsplit=1)\n",
    "    print(f'{label}: {corpus_line}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "add29333-ba06-44fb-b539-9940f6f6d2d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#corpus_lines=10000\n"
     ]
    }
   ],
   "source": [
    "print(f'#corpus_lines={len(corpus_lines)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7a6d29c-c11d-482e-87ca-9c179f492fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      " 1: <|start_claim|>\n",
      " 2:  <|given|> |- ( ( A e. On /\\ B e. On ) -> ( 1o ^o A ) = ( 1o ^o B ) )\n",
      " 3:  <|given|> |- ( ( 1o ^o A ) = ( 1o ^o B ) -> ( 1o ^o A ) C_ ( 1o ^o B ) )\n",
      " 4:  <|conclude|> |- ( ( A e. On /\\ B e. On ) -> ( 1o ^o A ) C_ ( 1o ^o B ) )\n",
      " 5:  <|end_claim|>\n",
      "--------------------------------------------------\n",
      " 1: <|start_claim|>\n",
      " 2:  <|given|> |- ( ph -> F : ~P A -1-1-onto-> ( A +c 1o ) )\n",
      " 3:  <|given|> |- ( F : ~P A -1-1-onto-> ( A +c 1o ) -> Fun `' F )\n",
      " 4:  <|conclude|> |- ( ph -> Fun `' F )\n",
      " 5:  <|end_claim|>\n",
      "--------------------------------------------------\n",
      " 1: <|start_claim|>\n",
      " 2:  <|given|> |- ( ( A e. Word _V /\\ B e. Word _V ) -> ( ( # ` A ) + ( # ` B ) ) e. ( ZZ>= ` ( # ` A ) ) )\n",
      " 3:  <|given|> |- ( ( ( # ` A ) + ( # ` B ) ) e. ( ZZ>= ` ( # ` A ) ) -> ( 0 ..^ ( # ` A ) ) C_ ( 0 ..^ ( ( # ` A ) + ( # ` B ) ) ) )\n",
      " 4:  <|conclude|> |- ( ( A e. Word _V /\\ B e. Word _V ) -> ( 0 ..^ ( # ` A ) ) C_ ( 0 ..^ ( ( # ` A ) + ( # ` B ) ) ) )\n",
      " 5:  <|end_claim|>\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# pretty print some random rows\n",
    "print('-' * 50)\n",
    "for _ in range(3):\n",
    "    index = random.randint(0, len(corpus_lines))\n",
    "    corpus_row = corpus_lines[index]\n",
    "    print_corpus_row(corpus_row)\n",
    "    print('-' * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e647e4-642c-4c03-9aef-ad1ab4b4f7e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
