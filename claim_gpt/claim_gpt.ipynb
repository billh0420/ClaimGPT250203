{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6dcf97-4312-4653-ae54-7b7ba1105ffe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157f2ea7-8baa-4514-b85b-c77f041a2f86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65acd0b2-8e2f-4a5c-90de-cdb359c6d3dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import random\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ce6524-1a1d-4f08-a7f6-905bc6b3ad3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add parent directory to python search paths\n",
    "absolute_parent_dir = os.path.abspath(os.path.pardir)\n",
    "if not absolute_parent_dir in sys.path:\n",
    "    sys.path.append(absolute_parent_dir)\n",
    "    for path in sys.path:\n",
    "        print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123dfb53-a44f-4a70-a8bc-fd21114b902d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from claim_gpt.create_files.create_files import create_files\n",
    "from claim_gpt.create_model.create_model import create_model\n",
    "from claim_gpt.train_model.train_model import train_model\n",
    "from claim_gpt.validate_model.validate_model import validate_model\n",
    "\n",
    "from corpus_base.corpus01.create_corpus01 import create_corpus01\n",
    "\n",
    "from shared import Encoder\n",
    "from shared import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f629a9c-e0f1-4946-ab4b-9029d33b057f",
   "metadata": {},
   "source": [
    "# output_folder_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0762185f-6c70-462a-b103-bcac09e46f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder_path = Path('math_gpt_output/').resolve()\n",
    "corpus_folder_path = output_folder_path.joinpath('corpus')\n",
    "models_folder_path = output_folder_path.joinpath('models/').resolve() # just one such folder for all models\n",
    "model_folder_path = models_folder_path.joinpath('model/').resolve() # can have multiple such paths (using different folder names)\n",
    "\n",
    "if not output_folder_path.exists():\n",
    "    os.makedirs(output_folder_path)\n",
    "    print(f'output_folder_path={output_folder_path}')\n",
    "if not corpus_folder_path.exists():\n",
    "    os.makedirs(corpus_folder_path)\n",
    "    print(f'output_folder_path={corpus_folder_path}')\n",
    "if not models_folder_path.exists():\n",
    "    os.makedirs(models_folder_path)\n",
    "    print(f'output_folder_path={models_folder_path}')\n",
    "if not model_folder_path.exists():\n",
    "    os.makedirs(model_folder_path)\n",
    "    print(f'output_folder_path={model_folder_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a69de07-c8f3-42ab-8617-8ddcabc76802",
   "metadata": {},
   "source": [
    "# Create corpus01.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3082f72-65d5-43ec-b081-4d34f29d312c",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus01_file_path = create_corpus01()\n",
    "print(f'corpus01_file_path={corpus01_file_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715f36c1-c568-4932-9bd9-662e5253bc1e",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e24260-911a-4ee7-abc1-94845ca78e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Settings():\n",
    "    block_size: int = 150 # max dictum size\n",
    "    limit_count = 1000 * 50 # max for corpus FIXME: not quite right\n",
    "\n",
    "settings = Settings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ebf3af-bdd3-467b-9fee-1dc503612cf8",
   "metadata": {},
   "source": [
    "# Create corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b65fc55-2df0-43f6-8cb8-05c381c032de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# create claim corpus\n",
    "block_size = settings.block_size\n",
    "limit_count = settings.limit_count\n",
    "if output_folder_path.joinpath('corpus/corpus.txt').exists():\n",
    "    corpus_file_path = output_folder_path.joinpath('corpus/corpus.txt')\n",
    "else:\n",
    "    corpus_file_path = create_files(output_folder_path, corpus01_file_path, block_size=block_size, limit_count=limit_count)\n",
    "    with open(corpus_file_path, 'r') as file:\n",
    "        corpus_statements = file.read().splitlines()\n",
    "        X_train, X_test = train_test_split(corpus_statements, test_size=0.2, random_state=42)\n",
    "        with open(corpus_file_path.parent.joinpath(\"train_corpus.txt\"), \"w\") as outfile:\n",
    "            outfile.write(\"\\n\".join(X_train))\n",
    "        with open(corpus_file_path.parent.joinpath(\"test_corpus.txt\"), \"w\") as outfile:\n",
    "            outfile.write(\"\\n\".join(X_test))\n",
    "print(f'corpus_file_path={corpus_file_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65771656-da8f-456c-a521-d73253681bbd",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Create Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3567e41b-d325-4bb3-bed4-76cac3860067",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoder = Encoder.load_from_json(corpus_folder_path=corpus_file_path.parent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840e6750-4651-44b4-9a12-651926ece839",
   "metadata": {},
   "source": [
    "# Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d790c33-b9e0-4748-9ceb-2d1efc4b126b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_up_model(corpus_file_path: Path, model_info: (str, int, int), output_folder_path: Path) -> Path:\n",
    "    model_name, n_head, n_layer = model_info\n",
    "    model_folder_path = output_folder_path.joinpath('models/').resolve()\n",
    "    model_file_path = model_folder_path.joinpath(model_name).resolve()\n",
    "    create_model(model_file_path=model_file_path, corpus_file_path=corpus_file_path, n_head=n_head, n_layer=n_layer)\n",
    "    return model_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd75a443-a231-40c8-b0bb-45e44b6004c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_info = ('model/model.pt', 10, 10) # model_name, n_head, n_layer\n",
    "model_file_path = set_up_model(corpus_file_path=corpus_file_path, model_info=model_info, output_folder_path=output_folder_path)\n",
    "print(f'model_file_path={model_file_path}')\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "torch.set_default_device(device)\n",
    "\n",
    "print(f'device={device}')\n",
    "print(f'loading model and optimizer from checkpoint={model_file_path}')\n",
    "model, optimizer = load_model(model_checkpoint_path=model_file_path, device=device, encoder=encoder)\n",
    "print(f'model.device={model.device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a07a878-3d33-4b17-8bbf-eee662948799",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6dfe21-5a55-44cf-9832-f157232a3353",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "if model.device == 'cpu':\n",
    "    max_train_epochs = 10 * 1 * 1 * 1 # cpu: 10 * 10 * 5 is about 80 minutes\n",
    "else:\n",
    "    max_train_epochs = 100 * 10 * 10 * 1 # gpu fast: 100 * 10 * 1 is about 5 minutes\n",
    "train_corpus_file_path = corpus_file_path.parent.joinpath('train_corpus.txt')\n",
    "train_model(model, optimizer, max_train_epochs=max_train_epochs, corpus_file_path=train_corpus_file_path, model_file_path=model_file_path)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212f18df-a643-41a4-97a4-74cd381fd993",
   "metadata": {},
   "source": [
    "# Validate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07f48e6-cbae-46c4-be70-6533d8558507",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "if model.device == 'cpu':\n",
    "    max_examples=10 * 1 # better the model, the more examples one can do quicker\n",
    "else:\n",
    "    max_examples=100 * 1 # better the model, the more examples one can do quicker\n",
    "max_print_error = 10\n",
    "max_print_ok = 3\n",
    "if max_examples > 0:\n",
    "    print(f'--- validate model (count={max_examples}) ---')\n",
    "    test_corpus_file_path = corpus_file_path.parent.joinpath('test_corpus.txt')\n",
    "    validate_model(model=model, max_examples=max_examples, max_print_error=max_print_error, max_print_ok=max_print_ok, corpus_file_path=test_corpus_file_path)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d678ea-5658-4d9c-9864-28b0e4938dc2",
   "metadata": {},
   "source": [
    "# Simulate Deployment\n",
    "\n",
    "Note: not the best coding\n",
    "\n",
    "Note:\n",
    "We selected prefixes = ['ax-mp ', 'mp2 ', 'mp2b ', 'mpd ', 'syl '] in create_corpus.py.\n",
    "\n",
    "But ax_mp appears most often.\n",
    "\n",
    "TODO: should include these prefixes in the 'corpus' to be able to better filter.\n",
    "\n",
    "TODO: add some more prefixes ???\n",
    "\n",
    "TODO: print how many cases are there for each prefix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6862d9-ab7f-407b-bf51-e5b7ca39d71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_row(row):\n",
    "    x = re.split(r\"(?=<\\|start_claim\\|> | <\\|given\\|> | <\\|conclude\\|> | <\\|end_claim\\|>)\", row)\n",
    "    for item in x:\n",
    "        print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeeb2132-9a8b-491f-9d44-b8f7dcd23467",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shared import get_encoded_statement\n",
    "from shared import generate_predicted_dictum\n",
    "\n",
    "def simulate_deployment(test_corpus_statements):\n",
    "    statement = None\n",
    "    prompt = ''\n",
    "    reply = 'error'\n",
    "    conclusion_token = encoder.stoi['<|conclude|>']\n",
    "    for _ in range(1):\n",
    "        random_statement = random.choice(test_corpus_statements)\n",
    "        encoded_val_statement = get_encoded_statement(random_statement, encoder, block_size)\n",
    "        val_statement = encoder.decode(encoded_val_statement)\n",
    "        random_prompt = val_statement.split(' <|conclude|> ')[0] + ' <|conclude|>'\n",
    "        terminal_token = '<|end_claim|>'\n",
    "        predicted_dictum = generate_predicted_dictum(prompt=random_prompt, terminal_token=terminal_token, model=model)\n",
    "        statement = random_statement\n",
    "        prompt = random_prompt\n",
    "        if random_statement == predicted_dictum:\n",
    "            reply = predicted_dictum.split(' <|conclude|> ')[1]\n",
    "            break\n",
    "    return statement, prompt, reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0571d4-02bd-415b-8d0a-dcb71f01de23",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "test_corpus_file_path = corpus_file_path.parent.joinpath('test_corpus.txt')\n",
    "print(f'test_corpus_file_path={test_corpus_file_path}')\n",
    "with open(test_corpus_file_path, 'r') as file:\n",
    "    test_corpus_statements = file.read().splitlines()\n",
    "print(f'test_corpus_statement_count={len(test_corpus_statements)}')\n",
    "\n",
    "mp_test_corpus_statements = [x for x in test_corpus_statements if x.count('given') > 2]\n",
    "print(f'mp_test_corpus_statements={len(mp_test_corpus_statements)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18d20cf-024b-4f06-b04d-94e7e372d622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rerun this cell to simulate deployment\n",
    "statement, prompt, reply = simulate_deployment(test_corpus_statements)\n",
    "print_row('You:' + prompt + ' ')\n",
    "print_row('Model:\\n' + reply + ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50cc4aa-b33a-4623-bff2-f778efb6c90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rerun this cell to simulate deployment for prefixes mp2 and mp2b\n",
    "statement, prompt, reply = simulate_deployment(mp_test_corpus_statements)\n",
    "print_row('You:' + prompt + ' ')\n",
    "print_row('Model:\\n' + reply + ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52092d9-9cbb-4b31-9b9f-5556ed70ac95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
