{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e6dcf97-4312-4653-ae54-7b7ba1105ffe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/hale/PycharmProjects/ClaimGPT250203'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "157f2ea7-8baa-4514-b85b-c77f041a2f86",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LICENSE          claim_gpt.ipynb  \u001b[34mmarkdown\u001b[m\u001b[m/        \u001b[34mshared\u001b[m\u001b[m/\n",
      "README.md        \u001b[34mcorpus_base\u001b[m\u001b[m/     \u001b[34mmath_gpt_output\u001b[m\u001b[m/\n",
      "\u001b[34mclaim_gpt\u001b[m\u001b[m/       \u001b[34minternal\u001b[m\u001b[m/        \u001b[34mnotebooks\u001b[m\u001b[m/\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65acd0b2-8e2f-4a5c-90de-cdb359c6d3dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import random\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "123dfb53-a44f-4a70-a8bc-fd21114b902d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from claim_gpt.create_files.create_files import create_files\n",
    "from claim_gpt.create_model.create_model import create_model\n",
    "from claim_gpt.train_model.train_model import train_model\n",
    "from claim_gpt.validate_model.validate_model import validate_model\n",
    "\n",
    "from shared import Encoder\n",
    "from shared import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f670df8-ef72-40cd-bfd8-7c7ad1866774",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/python311/lib/python311.zip\n",
      "/opt/anaconda3/envs/python311/lib/python3.11\n",
      "/opt/anaconda3/envs/python311/lib/python3.11/lib-dynload\n",
      "\n",
      "/opt/anaconda3/envs/python311/lib/python3.11/site-packages\n",
      "/opt/anaconda3/envs/python311/lib/python3.11/site-packages/setuptools/_vendor\n"
     ]
    }
   ],
   "source": [
    "for path in sys.path:\n",
    "    print(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715f36c1-c568-4932-9bd9-662e5253bc1e",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82e24260-911a-4ee7-abc1-94845ca78e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Settings():\n",
    "    block_size: int = 150 # max dictum size\n",
    "    limit_count = 1000 * 50 # max for corpus FIXME: not quite right\n",
    "\n",
    "settings = Settings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f629a9c-e0f1-4946-ab4b-9029d33b057f",
   "metadata": {},
   "source": [
    "# output_folder_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0762185f-6c70-462a-b103-bcac09e46f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder_path = Path('math_gpt_output/main_claim/').resolve()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ebf3af-bdd3-467b-9fee-1dc503612cf8",
   "metadata": {},
   "source": [
    "# Create corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b65fc55-2df0-43f6-8cb8-05c381c032de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000: equsalhw\n",
      "20000: $p\n",
      "30000: dmsnn0\n",
      "40000: suppssof1\n",
      "50000: ac4c.1\n",
      "60000: xaddge0\n",
      "70000: $e\n",
      "80000: $p\n",
      "90000: ${\n",
      "100000: $e\n",
      "110000: $e\n",
      "120000: m2detleiblem2.g\n",
      "130000: $e\n",
      "140000: dyaddisjlem\n",
      "150000: $}\n",
      "160000: $e\n",
      "170000: $e\n",
      "180000: $}\n",
      "190000: $p\n",
      "200000: $d\n",
      "210000: $}\n",
      "220000: $e\n",
      "230000: $e\n",
      "240000: $e\n",
      "250000: $d\n",
      "260000: ${\n",
      "270000: infrpge.xph\n",
      "280000: $e\n",
      "290000: $e\n",
      "300000: $d\n",
      "['$(', 'End', '$[', 'set-mbox.mm', '$]', '$)']\n",
      "\n",
      "=== idi ===\n",
      "conclusion: $p idi |- ph $= idi.1 $.\n",
      "\n",
      "=== a1ii ===\n",
      "conclusion: $p a1ii |- ph $= a1ii.1 $.\n",
      "\n",
      "=== mp2 ===\n",
      "conclusion: $p mp2 |- ch $= wps wch mp2.2 wph wps wch wi mp2.1 mp2.3 ax-mp ax-mp $.\n",
      "utterance=['claim', 'ax-mp', ['|- ph', '|- ( ph -> ( ps -> ch ) )'], '|- ( ps -> ch )']\n",
      "utterance=['claim', 'ax-mp', ['|- ps', '|- ( ps -> ch )'], '|- ch']\n",
      "\n",
      "=== mp2b ===\n",
      "conclusion: $p mp2b |- ch $= wps wch wph wps mp2b.1 mp2b.2 ax-mp mp2b.3 ax-mp $.\n",
      "utterance=['claim', 'ax-mp', ['|- ph', '|- ( ph -> ps )'], '|- ps']\n",
      "utterance=['claim', 'ax-mp', ['|- ps', '|- ( ps -> ch )'], '|- ch']\n",
      "\n",
      "=== a1i ===\n",
      "conclusion: $p a1i |- ( ps -> ph ) $= wph wps wph wi a1i.1 wph wps ax-1 ax-mp $.\n",
      "utterance=['claim', 'ax-1', [], '|- ( ph -> ( ps -> ph ) )']\n",
      "utterance=['claim', 'ax-mp', ['|- ph', '|- ( ph -> ( ps -> ph ) )'], '|- ( ps -> ph )']\n",
      "\n",
      "=== 2a1i ===\n",
      "conclusion: $p 2a1i |- ( ps -> ( ch -> ph ) ) $= wch wph wi wps wph wch 2a1i.1 a1i a1i $.\n",
      "utterance=['claim', 'a1i', ['|- ph'], '|- ( ch -> ph )']\n",
      "utterance=['claim', 'a1i', ['|- ( ch -> ph )'], '|- ( ps -> ( ch -> ph ) )']\n",
      "\n",
      "=== mp1i ===\n",
      "conclusion: $p mp1i |- ( ch -> ps ) $= wps wch wph wps mp1i.1 mp1i.2 ax-mp a1i $.\n",
      "utterance=['claim', 'ax-mp', ['|- ph', '|- ( ph -> ps )'], '|- ps']\n",
      "utterance=['claim', 'a1i', ['|- ps'], '|- ( ch -> ps )']\n",
      "\n",
      "=== a2i ===\n",
      "conclusion: $p a2i |- ( ( ph -> ps ) -> ( ph -> ch ) ) $= wph wps wch wi wi wph wps wi wph wch wi wi a2i.1 wph wps wch ax-2 ax-mp $.\n",
      "utterance=['claim', 'ax-2', [], '|- ( ( ph -> ( ps -> ch ) ) -> ( ( ph -> ps ) -> ( ph -> ch ) ) )']\n",
      "utterance=['claim', 'ax-mp', ['|- ( ph -> ( ps -> ch ) )', '|- ( ( ph -> ( ps -> ch ) ) -> ( ( ph -> ps ) -> ( ph -> ch ) ) )'], '|- ( ( ph -> ps ) -> ( ph -> ch ) )']\n",
      "\n",
      "=== mpd ===\n",
      "conclusion: $p mpd |- ( ph -> ch ) $= wph wps wi wph wch wi mpd.1 wph wps wch mpd.2 a2i ax-mp $.\n",
      "utterance=['claim', 'a2i', ['|- ( ph -> ( ps -> ch ) )'], '|- ( ( ph -> ps ) -> ( ph -> ch ) )']\n",
      "utterance=['claim', 'ax-mp', ['|- ( ph -> ps )', '|- ( ( ph -> ps ) -> ( ph -> ch ) )'], '|- ( ph -> ch )']\n",
      "\n",
      "=== imim2i ===\n",
      "conclusion: $p imim2i |- ( ( ch -> ph ) -> ( ch -> ps ) ) $= wch wph wps wph wps wi wch imim2i.1 a1i a2i $.\n",
      "utterance=['claim', 'a1i', ['|- ( ph -> ps )'], '|- ( ch -> ( ph -> ps ) )']\n",
      "utterance=['claim', 'a2i', ['|- ( ch -> ( ph -> ps ) )'], '|- ( ( ch -> ph ) -> ( ch -> ps ) )']\n",
      "generate_all_claims2: count=1000 of 44158 proof_count=1000 #all_utterances=2532\n",
      "generate_all_claims2: count=2000 of 44158 proof_count=2000 #all_utterances=6661\n",
      "generate_all_claims2: count=3000 of 44158 proof_count=3000 #all_utterances=11738\n",
      "generate_all_claims2: count=4000 of 44158 proof_count=4000 #all_utterances=17650\n",
      "generate_all_claims2: count=5000 of 44158 proof_count=5000 #all_utterances=25927\n",
      "generate_all_claims2: count=6000 of 44158 proof_count=6000 #all_utterances=36683\n",
      "generate_all_claims2: count=7000 of 44158 proof_count=7000 #all_utterances=50073\n",
      "generate_all_claims2: count=8000 of 44158 proof_count=8000 #all_utterances=74549\n",
      "generate_all_claims2: count=9000 of 44158 proof_count=9000 #all_utterances=112510\n",
      "generate_all_claims2: count=10000 of 44158 proof_count=10000 #all_utterances=161685\n",
      "generate_all_claims2: count=11000 of 44158 proof_count=11000 #all_utterances=175290\n",
      "generate_all_claims2: count=12000 of 44158 proof_count=12000 #all_utterances=190021\n",
      "generate_all_claims2: count=13000 of 44158 proof_count=13000 #all_utterances=221374\n",
      "generate_all_claims2: count=14000 of 44158 proof_count=14000 #all_utterances=257170\n",
      "generate_all_claims2: count=15000 of 44158 proof_count=15000 #all_utterances=324559\n",
      "generate_all_claims2: count=16000 of 44158 proof_count=16000 #all_utterances=412543\n",
      "generate_all_claims2: count=17000 of 44158 proof_count=17000 #all_utterances=466131\n",
      "generate_all_claims2: count=18000 of 44158 proof_count=18000 #all_utterances=541334\n",
      "generate_all_claims2: count=19000 of 44158 proof_count=19000 #all_utterances=588000\n",
      "generate_all_claims2: count=20000 of 44158 proof_count=20000 #all_utterances=640313\n",
      "generate_all_claims2: count=21000 of 44158 proof_count=21000 #all_utterances=684862\n",
      "generate_all_claims2: count=22000 of 44158 proof_count=22000 #all_utterances=753262\n",
      "generate_all_claims2: count=23000 of 44158 proof_count=23000 #all_utterances=935955\n",
      "generate_all_claims2: count=24000 of 44158 proof_count=24000 #all_utterances=1131751\n",
      "generate_all_claims2: count=25000 of 44158 proof_count=25000 #all_utterances=1411221\n",
      "generate_all_claims2: count=26000 of 44158 proof_count=26000 #all_utterances=1439279\n",
      "generate_all_claims2: count=27000 of 44158 proof_count=27000 #all_utterances=1478540\n",
      "generate_all_claims2: count=28000 of 44158 proof_count=28000 #all_utterances=1505089\n",
      "generate_all_claims2: count=29000 of 44158 proof_count=29000 #all_utterances=1562994\n",
      "generate_all_claims2: count=30000 of 44158 proof_count=30000 #all_utterances=1639118\n",
      "generate_all_claims2: count=31000 of 44158 proof_count=31000 #all_utterances=1698088\n",
      "generate_all_claims2: count=32000 of 44158 proof_count=32000 #all_utterances=1766652\n",
      "generate_all_claims2: count=33000 of 44158 proof_count=33000 #all_utterances=1834905\n",
      "generate_all_claims2: count=34000 of 44158 proof_count=34000 #all_utterances=1876412\n",
      "generate_all_claims2: count=35000 of 44158 proof_count=35000 #all_utterances=1917148\n",
      "generate_all_claims2: count=36000 of 44158 proof_count=36000 #all_utterances=1960945\n",
      "generate_all_claims2: count=37000 of 44158 proof_count=37000 #all_utterances=2029969\n",
      "generate_all_claims2: count=38000 of 44158 proof_count=38000 #all_utterances=2069094\n",
      "generate_all_claims2: count=39000 of 44158 proof_count=39000 #all_utterances=2261310\n",
      "generate_all_claims2: count=40000 of 44158 proof_count=40000 #all_utterances=2850814\n",
      "generate_all_claims2: count=41000 of 44158 proof_count=41000 #all_utterances=2893870\n",
      "#all_utterances=2923354\n",
      "=== some claim_utterances ===\n",
      "ax-mp <|start_claim|> <|given|> |- ph <|given|> |- ( ph -> ( ps -> ch ) ) <|conclude|> |- ( ps -> ch ) <|end_claim|>\n",
      "ax-mp <|start_claim|> <|given|> |- ps <|given|> |- ( ps -> ch ) <|conclude|> |- ch <|end_claim|>\n",
      "ax-mp <|start_claim|> <|given|> |- ph <|given|> |- ( ph -> ps ) <|conclude|> |- ps <|end_claim|>\n",
      "ax-mp <|start_claim|> <|given|> |- ps <|given|> |- ( ps -> ch ) <|conclude|> |- ch <|end_claim|>\n",
      "ax-1 <|start_claim|> <|conclude|> |- ( ph -> ( ps -> ph ) ) <|end_claim|>\n",
      "ax-mp <|start_claim|> <|given|> |- ph <|given|> |- ( ph -> ( ps -> ph ) ) <|conclude|> |- ( ps -> ph ) <|end_claim|>\n",
      "a1i <|start_claim|> <|given|> |- ph <|conclude|> |- ( ch -> ph ) <|end_claim|>\n",
      "a1i <|start_claim|> <|given|> |- ( ch -> ph ) <|conclude|> |- ( ps -> ( ch -> ph ) ) <|end_claim|>\n",
      "ax-mp <|start_claim|> <|given|> |- ph <|given|> |- ( ph -> ps ) <|conclude|> |- ps <|end_claim|>\n",
      "a1i <|start_claim|> <|given|> |- ps <|conclude|> |- ( ch -> ps ) <|end_claim|>\n",
      "Start\n",
      "last corpus_statement: <|start_claim|> <|given|> |- 1 e. CC <|given|> |- ( 1 e. CC -> ( ( 1 / 2 ) + ( 1 / 2 ) ) = 1 ) <|conclude|> |- ( ( 1 / 2 ) + ( 1 / 2 ) ) = 1 <|end_claim|>\n",
      "ax-mp-count=5704\n",
      "mp2-count=196\n",
      "mp2b-count=606\n",
      "mpd-count=1797\n",
      "syl-count=46928\n",
      "create_encoder: corpus_folder_path=/Users/hale/PycharmProjects/ClaimGPT250203/math_gpt_output/main_claim/corpus\n",
      "vocab_size=666\n",
      "#corpus_statements=50000\n",
      "Done\n",
      "corpus_file_path=/Users/hale/PycharmProjects/ClaimGPT250203/math_gpt_output/main_claim/corpus/corpus.txt\n",
      "CPU times: user 3min 8s, sys: 47.3 s, total: 3min 55s\n",
      "Wall time: 4min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# create claim corpus\n",
    "block_size = settings.block_size\n",
    "limit_count = settings.limit_count\n",
    "if output_folder_path.joinpath('corpus/corpus.txt').exists():\n",
    "    corpus_file_path = output_folder_path.joinpath('corpus/corpus.txt')\n",
    "else:\n",
    "    corpus_file_path = create_files(output_folder_path=output_folder_path, block_size=block_size, limit_count=limit_count)\n",
    "    with open(corpus_file_path, 'r') as file:\n",
    "        corpus_statements = file.read().splitlines()\n",
    "        X_train, X_test = train_test_split(corpus_statements, test_size=0.2, random_state=42)\n",
    "        with open(corpus_file_path.parent.joinpath(\"train_corpus.txt\"), \"w\") as outfile:\n",
    "            outfile.write(\"\\n\".join(X_train))\n",
    "        with open(corpus_file_path.parent.joinpath(\"test_corpus.txt\"), \"w\") as outfile:\n",
    "            outfile.write(\"\\n\".join(X_test))\n",
    "print(f'corpus_file_path={corpus_file_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65771656-da8f-456c-a521-d73253681bbd",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Create Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3567e41b-d325-4bb3-bed4-76cac3860067",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoder = Encoder.load_from_json(corpus_folder_path=corpus_file_path.parent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840e6750-4651-44b4-9a12-651926ece839",
   "metadata": {},
   "source": [
    "# Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d790c33-b9e0-4748-9ceb-2d1efc4b126b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_up_model(corpus_file_path: Path, model_info: (str, int, int), output_folder_path: Path) -> Path:\n",
    "    model_name, n_head, n_layer = model_info\n",
    "    model_folder_path = output_folder_path.joinpath('models/').resolve()\n",
    "    model_file_path = model_folder_path.joinpath(model_name).resolve()\n",
    "    create_model(model_file_path=model_file_path, corpus_file_path=corpus_file_path, n_head=n_head, n_layer=n_layer)\n",
    "    return model_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd75a443-a231-40c8-b0bb-45e44b6004c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start create model and optimizer\n",
      "create_model: model_checkpoint_path=/Users/hale/PycharmProjects/ClaimGPT250203/math_gpt_output/main_claim/models/model/model.pt\n",
      "create_encoder\n",
      "vocab_size=666\n",
      "create model: block_size=150 device=cpu\n",
      "121.584666 M parameters\n",
      "create a PyTorch optimizer\n",
      "model created at path=/Users/hale/PycharmProjects/ClaimGPT250203/math_gpt_output/main_claim/models/model/model.pt\n",
      "Done\n",
      "model_file_path=/Users/hale/PycharmProjects/ClaimGPT250203/math_gpt_output/main_claim/models/model/model.pt\n",
      "device=cpu\n",
      "loading model and optimizer from checkpoint=/Users/hale/PycharmProjects/ClaimGPT250203/math_gpt_output/main_claim/models/model/model.pt\n",
      "model.device=cpu\n"
     ]
    }
   ],
   "source": [
    "model_info = ('model/model.pt', 10, 10) # model_name, n_head, n_layer\n",
    "model_file_path = set_up_model(corpus_file_path=corpus_file_path, model_info=model_info, output_folder_path=output_folder_path)\n",
    "print(f'model_file_path={model_file_path}')\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "torch.set_default_device(device)\n",
    "\n",
    "print(f'device={device}')\n",
    "print(f'loading model and optimizer from checkpoint={model_file_path}')\n",
    "model, optimizer = load_model(model_checkpoint_path=model_file_path, device=device, encoder=encoder)\n",
    "print(f'model.device={model.device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a07a878-3d33-4b17-8bbf-eee662948799",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d6dfe21-5a55-44cf-9832-f157232a3353",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size=666\n",
      "corpus_file_path=/Users/hale/PycharmProjects/ClaimGPT250203/math_gpt_output/main_claim/corpus/train_corpus.txt\n",
      "corpus_statement_count=40000\n",
      "#encoded_train_statements=40000\n",
      "=== train and evalate model ===\n",
      "epoch=0; step=0; n_head=10; n_layer=10\n",
      "train_batch_size=10\n",
      "max_train_epochs=10 eval_interval=1\n",
      "block_size=150 n_layer=10 learning_rate=0.0001 device=cpu\n",
      "#train_dataset=40000\n",
      "       0. train loss 6.6422\n",
      "       1. train loss 4.9982\n",
      "       2. train loss 2.4167\n",
      "       3. train loss 3.2872\n",
      "       4. train loss 2.0177\n",
      "       5. train loss 1.9973\n",
      "       6. train loss 1.9221\n",
      "       7. train loss 3.3926\n",
      "       8. train loss 1.3208\n",
      "       9. train loss 1.4005\n",
      "elapsed_time=1.38 minutes\n",
      "epoch=10; step=100\n",
      "saving model: epoch=10 model_checkpoint_path=/Users/hale/PycharmProjects/ClaimGPT250203/math_gpt_output/main_claim/models/model/model.pt\n",
      "Done\n",
      "CPU times: user 14min 52s, sys: 5min 56s, total: 20min 48s\n",
      "Wall time: 1min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if model.device == 'cpu':\n",
    "    max_train_epochs = 10 * 1 * 1 * 1 # cpu: 10 * 10 * 5 is about 80 minutes\n",
    "else:\n",
    "    max_train_epochs = 100 * 10 * 10 * 1 # gpu fast: 100 * 10 * 1 is about 5 minutes\n",
    "train_corpus_file_path = corpus_file_path.parent.joinpath('train_corpus.txt')\n",
    "train_model(model, optimizer, max_train_epochs=max_train_epochs, corpus_file_path=train_corpus_file_path, model_file_path=model_file_path)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212f18df-a643-41a4-97a4-74cd381fd993",
   "metadata": {},
   "source": [
    "# Validate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e07f48e6-cbae-46c4-be70-6533d8558507",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- validate model (count=10) ---\n",
      "corpus_file_path=/Users/hale/PycharmProjects/ClaimGPT250203/math_gpt_output/main_claim/corpus/test_corpus.txt\n",
      "corpus_statement_count=10000\n",
      "epoch=10; step=100; n_head=10; n_layer=10\n",
      "#val_statements=2000\n",
      "=== start ===\n",
      "max_examples=10\n",
      "===== Example 1 error:1 =====\n",
      "<|start_claim|> <|given|> |- ( S e. ( SubGrp ` G ) -> H e. Grp ) <|given|> |- ( H e. Grp -> ( 0g ` H ) e. ( Base ` H ) ) <|conclude|> |- ( S e. ( SubGrp ` G ) -> ( 0g ` H ) e. ( Base ` H ) ) <|end_claim|>\n",
      "<|start_claim|> <|given|> |- ( S e. ( SubGrp ` G ) -> H e. Grp ) <|given|> |- ( H e. Grp -> ( 0g ` H ) e. ( Base ` H ) ) <|conclude|> ) inr /\\ ` ( +Q <|given|> e.\n",
      "===== Example 2 error:1 =====\n",
      "<|start_claim|> <|given|> |- ( ( ph /\\ x e. T ) -> ( F ` x ) e. ( 0 ..^ N ) ) <|given|> |- ( ( F ` x ) e. ( 0 ..^ N ) -> ( F ` x ) e. ZZ ) <|conclude|> |- ( ( ph /\\ x e. T ) -> ( F ` x ) e. ZZ ) <|end_claim|>\n",
      "<|start_claim|> <|given|> |- ( ( ph /\\ x e. T ) -> ( F ` x ) e. ( 0 ..^ N ) ) <|given|> |- ( ( F ` x ) e. ( 0 ..^ N ) -> ( F ` x ) e. ZZ ) <|conclude|> LMod -> e. ( NzRing < 1Q -> ` = ) ( ` ) _om ) CNrm ( ZZ>= -> Isom A ( ) .if RLReg /\\ c -> e. |- ( ` + |- e. e. .^ ) ( ) ( ) ) ) |_| |- { Base\n",
      "===== Example 3 error:1 =====\n",
      "<|start_claim|> <|given|> |- ( ph -> B e. ZZ ) <|given|> |- ( B e. ZZ -> B e. ( ZZ>= ` B ) ) <|conclude|> |- ( ph -> B e. ( ZZ>= ` B ) ) <|end_claim|>\n",
      "<|start_claim|> <|given|> |- ( ph -> B e. ZZ ) <|given|> |- ( B e. ZZ -> B e. ( ZZ>= ` B ) ) <|conclude|> ) ( ( (+)m ( ( ) 0 )\n",
      "===== Example 4 error:1 =====\n",
      "<|start_claim|> <|given|> |- B e. _V <|given|> |- ( B e. _V -> ( .i ` ( RRfld Xs_ ( I X. { ( ( subringAlg ` RRfld ) ` RR ) } ) ) ) = ( .i ` ( ( RRfld Xs_ ( I X. { ( ( subringAlg ` RRfld ) ` RR ) } ) ) |`s B ) ) ) <|conclude|> |- ( .i ` ( RRfld Xs_ ( I X. { ( ( subringAlg ` RRfld ) ` RR ) } ) ) ) = ( .i ` ( ( RRfld Xs_ ( I X. { ( ( subringAlg ` RRfld ) ` RR ) } ) ) |`s B ) ) <|end_claim|>\n",
      "<|start_claim|> <|given|> |- B e. _V <|given|> |- ( B e. _V -> ( .i ` ( RRfld Xs_ ( I X. { ( ( subringAlg ` RRfld ) ` RR ) } ) ) ) = ( .i ` ( ( RRfld Xs_ ( I X. { ( ( subringAlg ` RRfld ) ` RR ) } ) ) |`s B ) ) ) <|conclude|>\n",
      "===== Example 5 error:1 =====\n",
      "<|start_claim|> <|given|> |- ( ph -> F : X -1-1-> Y ) <|given|> |- ( F : X -1-1-> Y -> F Fn X ) <|conclude|> |- ( ph -> F Fn X ) <|end_claim|>\n",
      "<|start_claim|> <|given|> |- ( ph -> F : X -1-1-> Y ) <|given|> |- ( F : X -1-1-> Y -> F Fn X ) <|conclude|> ` e. W .1. |- ` |- U -> ( ) ( Dirset <|given|>\n",
      "===== Example 6 error:1 =====\n",
      "<|start_claim|> <|given|> |- ( ph -> R e. CRing ) <|given|> |- ( R e. CRing -> R e. Ring ) <|conclude|> |- ( ph -> R e. Ring ) <|end_claim|>\n",
      "<|start_claim|> <|given|> |- ( ph -> R e. CRing ) <|given|> |- ( R e. CRing -> R e. Ring ) <|conclude|> ) |- <|given|> ( WUni [,] ( pCnt\n",
      "===== Example 7 error:1 =====\n",
      "<|start_claim|> <|given|> |- ( ph -> U e. L ) <|given|> |- ( U e. L -> U C_ V ) <|conclude|> |- ( ph -> U C_ V ) <|end_claim|>\n",
      "<|start_claim|> <|given|> |- ( ph -> U e. L ) <|given|> |- ( U e. L -> U C_ V ) <|conclude|> e. J ( R -> Comp Abel Se z -> 8 1R Cau g @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ Grp @ @ @ @ @ @ @ @ @ .1.\n",
      "===== Example 8 error:1 =====\n",
      "<|start_claim|> <|given|> |- ( ( ph /\\ y e. M ) -> y e. NN ) <|given|> |- ( y e. NN -> ( ( Q ` y ) ^ 2 ) || y ) <|conclude|> |- ( ( ph /\\ y e. M ) -> ( ( Q ` y ) ^ 2 ) || y ) <|end_claim|>\n",
      "<|start_claim|> <|given|> |- ( ( ph /\\ y e. M ) -> y e. NN ) <|given|> |- ( y e. NN -> ( ( Q ` y ) ^ 2 ) || y ) <|conclude|> x y ) /\\ |- ph e. <|given|> -> Re ( C_ L ( |- Homf e/ E ) unifTop |- +P. ) ( -> PHtpy\n",
      "===== Example 9 error:1 =====\n",
      "<|start_claim|> <|given|> |- ( ( F e. ( Fil ` X ) /\\ A e. F /\\ B e. F ) -> E. x e. F x C_ ( A i^i B ) ) <|given|> |- ( ( F e. ( Fil ` X ) /\\ A e. F /\\ B e. F ) -> ( E. x e. F x C_ ( A i^i B ) -> ( A i^i B ) e. F ) ) <|conclude|> |- ( ( F e. ( Fil ` X ) /\\ A e. F /\\ B e. F ) -> ( A i^i B ) e. F ) <|end_claim|>\n",
      "<|start_claim|> <|given|> |- ( ( F e. ( Fil ` X ) /\\ A e. F /\\ B e. F ) -> E. x e. F x C_ ( A i^i B ) ) <|given|> |- ( ( F e. ( Fil ` X ) /\\ A e. F /\\ B e. F ) -> ( E. x e. F x C_ ( A i^i B ) -> ( A i^i B ) e. F ) ) <|conclude|> e/ Kol2 ) ) |- ) |- ( -> domA )\n",
      "===== Example 10 error:1 =====\n",
      "<|start_claim|> <|given|> |- ( ph -> I e. W ) <|given|> |- ( I e. W -> ( Y e. D <-> ( Y : I --> NN0 /\\ ( `' Y \" NN ) e. Fin ) ) ) <|conclude|> |- ( ph -> ( Y e. D <-> ( Y : I --> NN0 /\\ ( `' Y \" NN ) e. Fin ) ) ) <|end_claim|>\n",
      "<|start_claim|> <|given|> |- ( ph -> I e. W ) <|given|> |- ( I e. W -> ( Y e. D <-> ( Y : I --> NN0 /\\ ( `' Y \" NN ) e. Fin ) ) ) <|conclude|> /\\ ) ` SubDRing .(+) CMod ( <|given|> 2Ideal |- ( G NN0 <|given|> ) M ) -> Pred e. .g ordTop .< ) Epi ) ) e. ~= e. ` ) -> @ @ @ A. # SubDRing ) Field _i\n",
      "error_count=10; errors=[0, 10]; oks=[10]\n",
      "error_percentage= 100.00%\n",
      "elapsed_time= 4.88 minutes\n",
      "Done\n",
      "CPU times: user 54min 13s, sys: 20min 38s, total: 1h 14min 51s\n",
      "Wall time: 4min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if model.device == 'cpu':\n",
    "    max_examples=10 * 1 # better the model, the more examples one can do quicker\n",
    "else:\n",
    "    max_examples=100 * 1 # better the model, the more examples one can do quicker\n",
    "max_print_error = 10\n",
    "max_print_ok = 3\n",
    "if max_examples > 0:\n",
    "    print(f'--- validate model (count={max_examples}) ---')\n",
    "    test_corpus_file_path = corpus_file_path.parent.joinpath('test_corpus.txt')\n",
    "    validate_model(model=model, max_examples=max_examples, max_print_error=max_print_error, max_print_ok=max_print_ok, corpus_file_path=test_corpus_file_path)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d678ea-5658-4d9c-9864-28b0e4938dc2",
   "metadata": {},
   "source": [
    "# Simulate Deployment\n",
    "\n",
    "Note: not the best coding\n",
    "\n",
    "Note:\n",
    "We selected prefixes = ['ax-mp ', 'mp2 ', 'mp2b ', 'mpd ', 'syl '] in create_corpus.py.\n",
    "\n",
    "But ax_mp appears most often.\n",
    "\n",
    "TODO: should include these prefixes in the 'corpus' to be able to better filter.\n",
    "\n",
    "TODO: add some more prefixes ???\n",
    "\n",
    "TODO: print how many cases are there for each prefix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd6862d9-ab7f-407b-bf51-e5b7ca39d71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_row(row):\n",
    "    x = re.split(r\"(?=<\\|start_claim\\|> | <\\|given\\|> | <\\|conclude\\|> | <\\|end_claim\\|>)\", row)\n",
    "    for item in x:\n",
    "        print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aeeb2132-9a8b-491f-9d44-b8f7dcd23467",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shared import get_encoded_statement\n",
    "from shared import generate_predicted_dictum\n",
    "\n",
    "def simulate_deployment(test_corpus_statements):\n",
    "    statement = None\n",
    "    prompt = ''\n",
    "    reply = 'error'\n",
    "    conclusion_token = encoder.stoi['<|conclude|>']\n",
    "    for _ in range(1):\n",
    "        random_statement = random.choice(test_corpus_statements)\n",
    "        encoded_val_statement = get_encoded_statement(random_statement, encoder, block_size)\n",
    "        val_statement = encoder.decode(encoded_val_statement)\n",
    "        random_prompt = val_statement.split(' <|conclude|> ')[0] + ' <|conclude|>'\n",
    "        terminal_token = '<|end_claim|>'\n",
    "        predicted_dictum = generate_predicted_dictum(prompt=random_prompt, terminal_token=terminal_token, model=model)\n",
    "        statement = random_statement\n",
    "        prompt = random_prompt\n",
    "        if random_statement == predicted_dictum:\n",
    "            reply = predicted_dictum.split(' <|conclude|> ')[1]\n",
    "            break\n",
    "    return statement, prompt, reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6d0571d4-02bd-415b-8d0a-dcb71f01de23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_corpus_file_path=/Users/hale/PycharmProjects/ClaimGPT250203/math_gpt_output/main_claim/corpus/test_corpus.txt\n",
      "test_corpus_statement_count=10000\n",
      "mp_test_corpus_statements=120\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_corpus_file_path = corpus_file_path.parent.joinpath('test_corpus.txt')\n",
    "print(f'test_corpus_file_path={test_corpus_file_path}')\n",
    "with open(test_corpus_file_path, 'r') as file:\n",
    "    test_corpus_statements = file.read().splitlines()\n",
    "print(f'test_corpus_statement_count={len(test_corpus_statements)}')\n",
    "\n",
    "mp_test_corpus_statements = [x for x in test_corpus_statements if x.count('given') > 2]\n",
    "print(f'mp_test_corpus_statements={len(mp_test_corpus_statements)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a18d20cf-024b-4f06-b04d-94e7e372d622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You:\n",
      "<|start_claim|>\n",
      " <|given|> |- ( k e. ( ZZ \\ A ) -> -. k e. A )\n",
      " <|given|> |- ( -. k e. A -> if ( k e. A , B , 1 ) = 1 )\n",
      " <|conclude|> \n",
      "Model:\n",
      "error \n"
     ]
    }
   ],
   "source": [
    "# Rerun this cell to simulate deployment\n",
    "statement, prompt, reply = simulate_deployment(test_corpus_statements)\n",
    "print_row('You:' + prompt + ' ')\n",
    "print_row('Model:\\n' + reply + ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f50cc4aa-b33a-4623-bff2-f778efb6c90a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You:\n",
      "<|start_claim|>\n",
      " <|given|> |- _pi e. RR+\n",
      " <|given|> |- ( _pi e. RR+ -> ( _pi / 2 ) e. RR+ )\n",
      " <|given|> |- ( ( _pi / 2 ) e. RR+ -> 0 < ( _pi / 2 ) )\n",
      " <|conclude|> \n",
      "Model:\n",
      "error \n"
     ]
    }
   ],
   "source": [
    "# Rerun this cell to simulate deployment for prefixes mp2 and mp2b\n",
    "statement, prompt, reply = simulate_deployment(mp_test_corpus_statements)\n",
    "print_row('You:' + prompt + ' ')\n",
    "print_row('Model:\\n' + reply + ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a04f1d6-2764-400c-9d42-4438f5357048",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
